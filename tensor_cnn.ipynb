{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers, Model\n",
    "# Define the model with ResNet50 as the backbone\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.applications import ResNet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Set GPU growth to prevent memory hogging\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 16\n",
    "DATA_DIR = \"D:/spark-2022-stream-1\"       # Base folder\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "VAL_DIR = os.path.join(DATA_DIR, \"val\")\n",
    "TRAIN_LABEL_FILE = os.path.join(DATA_DIR, \"labels/train.csv\")\n",
    "VAL_LABEL_FILE = os.path.join(DATA_DIR, \"labels/val.csv\")\n",
    "NUM_CLASSES = 10                            # Number of object classes\n",
    "\n",
    "# Load bounding box annotations\n",
    "train_labels_df = pd.read_csv(TRAIN_LABEL_FILE)\n",
    "val_labels_df = pd.read_csv(VAL_LABEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generator Class\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, dataframe, data_dir, batch_size=BATCH_SIZE, img_size=IMG_SIZE, num_classes=NUM_CLASSES):\n",
    "        self.dataframe = dataframe\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.num_classes = num_classes\n",
    "        self.class_names = [\n",
    "            \"Cheops\", \"lisa_pathfinder\", \"ObservationSat1\", \"Proba2\", \"Proba3\", \n",
    "            \"Proba3ocs\", \"smart_1\", \"Soho\", \"VenusExpress\", \"XMM Newton\"\n",
    "        ]\n",
    "        self.class_mapping = {name: idx for idx, name in enumerate(self.class_names)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_df = self.dataframe.iloc[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        batch_images = []\n",
    "        batch_bboxes = []\n",
    "        batch_classes = []\n",
    "\n",
    "        for _, row in batch_df.iterrows():\n",
    "            try:\n",
    "                # Load and preprocess the image\n",
    "                image_path = os.path.join(self.data_dir, row['class'], row['filename'])\n",
    "                print(image_path)\n",
    "                if not os.path.exists(image_path):\n",
    "                    raise FileNotFoundError(f\"Image not found at path: {image_path}\")\n",
    "                image = tf.keras.preprocessing.image.load_img(image_path, target_size=(self.img_size, self.img_size), color_mode='rgb')\n",
    "                image = tf.keras.preprocessing.image.img_to_array(image) / 255.0\n",
    "                \n",
    "                # Scale bounding box coordinates to [0, 1] for the resized image\n",
    "                xmin, ymin, xmax, ymax = eval(row['bbox'])\n",
    "                bbox = [xmin / 1024, ymin / 1024, xmax / 1024, ymax / 1024]\n",
    "                \n",
    "                # One-hot encode the class label\n",
    "                class_id = self.class_mapping.get(row['class'], None)\n",
    "                if class_id is None:\n",
    "                    raise KeyError(f\"Class '{row['class']}' not found in class mapping.\")\n",
    "                class_one_hot = tf.keras.utils.to_categorical(class_id, num_classes=self.num_classes)\n",
    "                \n",
    "                batch_images.append(image)\n",
    "                batch_bboxes.append(bbox)\n",
    "                batch_classes.append(class_one_hot)\n",
    "            except (KeyError, FileNotFoundError) as e:\n",
    "                print(f\"Error: {e}. Skipping this row.\")\n",
    "\n",
    "        return np.array(batch_images, dtype=np.float64), {\"bbox\": np.array(batch_bboxes, dtype=np.float64), \"class\": np.array(batch_classes, dtype=np.float64)}\n",
    "\n",
    "# Create training and validation generators\n",
    "train_gen = DataGenerator(train_labels_df, data_dir=TRAIN_DIR, num_classes=NUM_CLASSES)\n",
    "val_gen = DataGenerator(val_labels_df, data_dir=VAL_DIR, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=NUM_CLASSES):\n",
    "    # Backbone network\n",
    "    backbone = ResNet50(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "    backbone.trainable = False  # Freeze the backbone\n",
    "    \n",
    "    # Flatten the backbone output\n",
    "    x = Flatten()(backbone.output)\n",
    "    \n",
    "    # Bounding box regression head\n",
    "    bbox_head = Dense(1024, activation=\"relu\")(x)\n",
    "    bbox_head = Dense(512, activation=\"relu\")(bbox_head)\n",
    "    bbox_output = Dense(4, activation=\"sigmoid\", name=\"bbox\")(bbox_head)  # Bounding box output [xmin, ymin, xmax, ymax]\n",
    "    \n",
    "    # Classification head\n",
    "    class_head = Dense(1024, activation=\"relu\")(x)\n",
    "    class_head = Dense(512, activation=\"relu\")(class_head)\n",
    "    class_output = Dense(num_classes, activation=\"softmax\", name=\"class\")(class_head)  # Class output\n",
    "    \n",
    "    # Define the model with two outputs\n",
    "    model = Model(inputs=backbone.input, outputs=[bbox_output, class_output])\n",
    "    return model\n",
    "\n",
    "# Initialize and compile the model\n",
    "model = create_model()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss={\n",
    "        \"bbox\": \"mse\",  # Loss for bounding box regression\n",
    "        \"class\": \"categorical_crossentropy\"  # Loss for classification\n",
    "    },\n",
    "    metrics={\"bbox\": \"mae\", \"class\": \"accuracy\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/spark-2022-stream-1\\train\\smart_1\\img086351.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img086351.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img083734.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img083734.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img081317.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img081317.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img089140.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img089140.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img082379.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img082379.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img089707.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img089707.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img080704.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img080704.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img088364.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img088364.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img089629.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img089629.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img088990.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img088990.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img087083.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img087083.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img080647.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img080647.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img089951.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img089951.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img084706.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img084706.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img086719.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img086719.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img080260.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img080260.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img084546.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img084546.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img084187.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img084187.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img081165.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img081165.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img083103.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img083103.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img084943.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img084943.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img080483.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img080483.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img081117.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img081117.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img080652.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img080652.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img086670.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img086670.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img089438.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img089438.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img089674.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img089674.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img084173.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img084173.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img088513.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img088513.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img081727.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img081727.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img088960.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img088960.png. Skipping this row.\n",
      "D:/spark-2022-stream-1\\train\\smart_1\\img089286.png\n",
      "Error: Image not found at path: D:/spark-2022-stream-1\\train\\smart_1\\img089286.png. Skipping this row.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vniko\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Functional.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"functional_12_1/Cast:0\", shape=(None,), dtype=float32). Expected shape (None, 256, 256, 3), but input has incompatible shape (None,)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs=tf.Tensor(shape=(None,), dtype=float64)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model with validation data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     11\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(val_gen)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\models\\functional.py:264\u001b[0m, in \u001b[0;36mFunctional._adjust_input_rank\u001b[1;34m(self, flat_inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m             adjusted\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    263\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m     )\n\u001b[0;32m    268\u001b[0m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Functional.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"functional_12_1/Cast:0\", shape=(None,), dtype=float32). Expected shape (None, 256, 256, 3), but input has incompatible shape (None,)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs=tf.Tensor(shape=(None,), dtype=float64)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with validation data\n",
    "EPOCHS = 10\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_gen,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model.evaluate(val_gen)\n",
    "print(\"Evaluation Results:\", evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
